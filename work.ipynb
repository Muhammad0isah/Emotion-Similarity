{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41cb9ac9-7e6a-4d73-9815-a4d7816f65e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "\n",
    "# Load the SBERT model\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Sample sentences for each emotion category\n",
    "anger_sentences = [\"The service was terrible.\", \"I am disgusted by the food.\"]\n",
    "joy_sentences = [\"The food was amazing!\", \"I loved the ambiance.\"]\n",
    "surprise_sentences = [\"I was shocked at how bad the food was!\", \"I couldnâ€™t believe how friendly the staff were.\"]\n",
    "\n",
    "# Compute embeddings for each category\n",
    "anger_embeddings = model.encode(anger_sentences, convert_to_tensor=True)\n",
    "joy_embeddings = model.encode(joy_sentences, convert_to_tensor=True)\n",
    "surprise_embeddings = model.encode(surprise_sentences, convert_to_tensor=True)\n",
    "\n",
    "# Calculate pairwise cosine similarities\n",
    "anger_joy_similarity = util.pytorch_cos_sim(anger_embeddings, joy_embeddings).mean().item()\n",
    "anger_surprise_similarity = util.pytorch_cos_sim(anger_embeddings, surprise_embeddings).mean().item()\n",
    "joy_surprise_similarity = util.pytorch_cos_sim(joy_embeddings, surprise_embeddings).mean().item()\n",
    "\n",
    "print(f\"Anger-Joy Similarity: {anger_joy_similarity}\")\n",
    "print(f\"Anger-Surprise Similarity: {anger_surprise_similarity}\")\n",
    "print(f\"Joy-Surprise Similarity: {joy_surprise_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c372893b-cc24-4e48-ae34-985a7cdabb78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Collect all embeddings and labels for clustering\n",
    "all_sentences = anger_sentences + joy_sentences + surprise_sentences\n",
    "all_embeddings = model.encode(all_sentences)\n",
    "\n",
    "# Reduce to 2D for visualization using t-SNE\n",
    "tsne = TSNE(n_components=2, random_state=0)\n",
    "reduced_embeddings = tsne.fit_transform(all_embeddings)\n",
    "\n",
    "# Plotting\n",
    "labels = ['Anger'] * len(anger_sentences) + ['Joy'] * len(joy_sentences) + ['Surprise'] * len(surprise_sentences)\n",
    "for label in set(labels):\n",
    "    indices = [i for i, l in enumerate(labels) if l == label]\n",
    "    plt.scatter(reduced_embeddings[indices, 0], reduced_embeddings[indices, 1], label=label)\n",
    "\n",
    "plt.legend()\n",
    "plt.title(\"t-SNE Visualization of Emotion Embeddings\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77708b3-060f-4758-88e6-50f01fce8494",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import BertTokenizer, BertModel\n",
    "import torch\n",
    "\n",
    "# Initialize BERT tokenizer and model\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "model = BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# Example sentences for each emotion\n",
    "anger_sentences = [\"The service was terrible and made me angry.\", \"I felt disgusted by the food quality.\"]\n",
    "joy_sentences = [\"The food was delightful and made me happy.\", \"I felt joyful with the excellent service.\"]\n",
    "surprise_sentences = [\"I was shocked at how bad the food was!\", \"I was surprised by the quick service.\"]\n",
    "\n",
    "# Define a function to compute SRD for a given sentence\n",
    "def calculate_srd(sentence, target_word):\n",
    "    # Tokenize the sentence\n",
    "    inputs = tokenizer(sentence, return_tensors=\"pt\")\n",
    "    tokens = tokenizer.convert_ids_to_tokens(inputs['input_ids'][0])\n",
    "    \n",
    "    # Get the index of the target word in the tokenized sentence\n",
    "    target_indices = [i for i, token in enumerate(tokens) if target_word in token]\n",
    "    \n",
    "    # Compute SRD by measuring distances between target indices and all other tokens\n",
    "    srd_scores = []\n",
    "    for target_index in target_indices:\n",
    "        distances = [abs(target_index - i) for i in range(len(tokens))]\n",
    "        srd_scores.append(distances)\n",
    "    \n",
    "    # Return average SRD for the target word in this sentence\n",
    "    avg_srd = np.mean(srd_scores)\n",
    "    return avg_srd\n",
    "\n",
    "# Define a function to calculate average SRD across sentences for an emotion category\n",
    "def average_srd_for_emotion(sentences, target_words):\n",
    "    srd_values = []\n",
    "    for sentence in sentences:\n",
    "        for word in target_words:\n",
    "            if word in sentence.lower():\n",
    "                srd = calculate_srd(sentence, word)\n",
    "                srd_values.append(srd)\n",
    "    return np.mean(srd_values)\n",
    "\n",
    "# Target words associated with each emotion\n",
    "anger_words = [\"angry\", \"disgusted\"]\n",
    "joy_words = [\"happy\", \"joyful\"]\n",
    "surprise_words = [\"surprised\", \"shocked\"]\n",
    "\n",
    "# Calculate SRD for each emotion category\n",
    "anger_srd = average_srd_for_emotion(anger_sentences, anger_words)\n",
    "joy_srd = average_srd_for_emotion(joy_sentences, joy_words)\n",
    "surprise_srd = average_srd_for_emotion(surprise_sentences, surprise_words)\n",
    "\n",
    "print(f\"Average SRD for Anger: {anger_srd}\")\n",
    "print(f\"Average SRD for Joy: {joy_srd}\")\n",
    "print(f\"Average SRD for Surprise: {surprise_srd}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
